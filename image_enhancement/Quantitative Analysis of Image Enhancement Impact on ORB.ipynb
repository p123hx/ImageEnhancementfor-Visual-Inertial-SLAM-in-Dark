{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsPA+n+VxZZIyBqe1Eze4s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IV6sdznMnjh0","executionInfo":{"status":"ok","timestamp":1680378002288,"user_tz":240,"elapsed":905,"user":{"displayName":"Awrod Haghi-Tabrizi","userId":"18367418826115770822"}},"outputId":"ba7c7aa8-2d15-43a6-84e4-ff95b12a2f20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","import glob\n","from matplotlib import pyplot as plt\n","import sys\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Set directory for all images in the dataset\n","dataset_path = '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Datasets/AHE 5'\n","\n","# Set if you want to display progress\n","display_images = False\n","verbose = True\n","\n","# Get the directory for the image_0 and image_1 paths\n","image_0_paths = sorted(glob.glob(f'{dataset_path}/image_0/*.png'))\n","image_1_paths = sorted(glob.glob(f'{dataset_path}/image_1/*.png'))\n","\n","# Check if the full dataset is picked up\n","if len(image_0_paths) != 456 or len(image_1_paths) != 456:\n","  print(f'ERROR - Full dataset not picked up\\n\\t{len(image_0_paths)=}\\n\\t{len(image_1_paths)=}\\n')\n","  sys.exit()\n","\n","# Initialize orb detector and matcher\n","orb = cv2.ORB_create()\n","bf = cv2.BFMatcher()\n","\n","# Setting the treshold ratio for the ratio test\n","ratio_threshold = .6\n","\n","# Initialize the number of good matches\n","num_good_matches = []\n","\n","# Loop through all the images in the dataset\n","for i in range(len(image_0_paths)-2):\n","\n","  # Get the current and next image_0 and image_1 image\n","  image_0_cur = cv2.imread(image_0_paths[i])\n","  image_1_cur = cv2.imread(image_1_paths[i])\n","  image_0_next = cv2.imread(image_0_paths[i+1])\n","  image_1_next = cv2.imread(image_1_paths[i+1])\n","    \n","  # Detect keypoints and descriptors\n","  image_0_cur_keypoints, image_0_cur_Descriptors = orb.detectAndCompute(image_0_cur, None)\n","  image_0_next_keypoints, image_0_next_Descriptors = orb.detectAndCompute(image_0_next, None)\n","  image_1_cur_keypoints, image_1_cur_Descriptors = orb.detectAndCompute(image_1_cur, None)\n","  image_1_next_keypoints, image_1_next_Descriptors = orb.detectAndCompute(image_1_next, None)\n","\n","  # Get matches\n","  image_0_matches = bf.knnMatch(image_0_cur_Descriptors, image_0_next_Descriptors, k=2)\n","  image_1_matches = bf.knnMatch(image_1_cur_Descriptors, image_1_next_Descriptors, k=2)\n","\n","  # Apply ratio test to keep only good matches\n","  image_0_good_matches = []\n","  image_1_good_matches = []\n","  for m,n in image_0_matches:\n","    if m.distance < ratio_threshold * n.distance:\n","      image_0_good_matches.append([m])\n","  for m,n in image_1_matches:\n","    if m.distance < ratio_threshold * n.distance:\n","      image_1_good_matches.append([m])\n","  \n","  # Keep track of the number of good matches\n","  num_good_matches.append( len(image_0_good_matches) + len(image_1_good_matches) )\n","\n","  # Display index\n","  if verbose and i % 10 == 0:\n","    print(f'Index {i} ...')\n","\n","  # Draw matches\n","  if display_images and i % 100 == 0:\n","    print(f'\\nimage_0')\n","    image_0 = cv2.drawMatchesKnn(image_0_cur, image_0_cur_keypoints, image_0_next, image_0_next_keypoints, image_0_good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","    image_0 = cv2.resize(image_0, (600,400))\n","    cv2_imshow(image_0)\n","    print('\\nimage_1')\n","    image_1 = cv2.drawMatchesKnn(image_1_cur, image_1_cur_keypoints, image_1_next, image_1_next_keypoints, image_1_good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","    image_1 = cv2.resize(image_1, (600,400))\n","    cv2_imshow(image_1)\n","    print()\n","\n","# Analyze\n","mean_num_good_matches = np.mean(num_good_matches)\n","cov_num_good_matches = np.cov(num_good_matches)\n","\n","# Create report\n","report = f'Number of good matches\\n'\n","report += f'\\t      Mean : {mean_num_good_matches}\\n'\n","report += f'\\tCovarience : {cov_num_good_matches}'\n","\n","# Export report\n","with open(f'{dataset_path}/Orb Analysis Report.txt', 'w') as f:\n","  f.write(report)\n","\n","# Print report\n","if verbose:\n","  print(f'\\n\\n{report}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GloMxbzFmfM6","executionInfo":{"status":"ok","timestamp":1680378343157,"user_tz":240,"elapsed":340215,"user":{"displayName":"Awrod Haghi-Tabrizi","userId":"18367418826115770822"}},"outputId":"01b43788-6971-43c0-df4d-dad16b2ea066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index 0 ...\n","Index 10 ...\n","Index 20 ...\n","Index 30 ...\n","Index 40 ...\n","Index 50 ...\n","Index 60 ...\n","Index 70 ...\n","Index 80 ...\n","Index 90 ...\n","Index 100 ...\n","Index 110 ...\n","Index 120 ...\n","Index 130 ...\n","Index 140 ...\n","Index 150 ...\n","Index 160 ...\n","Index 170 ...\n","Index 180 ...\n","Index 190 ...\n","Index 200 ...\n","Index 210 ...\n","Index 220 ...\n","Index 230 ...\n","Index 240 ...\n","Index 250 ...\n","Index 260 ...\n","Index 270 ...\n","Index 280 ...\n","Index 290 ...\n","Index 300 ...\n","Index 310 ...\n","Index 320 ...\n","Index 330 ...\n","Index 340 ...\n","Index 350 ...\n","Index 360 ...\n","Index 370 ...\n","Index 380 ...\n","Index 390 ...\n","Index 400 ...\n","Index 410 ...\n","Index 420 ...\n","Index 430 ...\n","Index 440 ...\n","Index 450 ...\n","\n","\n","Number of good matches\n","\t      Mean : 94.61453744493392\n","\tCovarience : 2969.6546226332525\n"]}]}]}