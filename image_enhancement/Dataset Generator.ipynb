{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1680979907752,"user":{"displayName":"Awrod Haghi-Tabrizi","userId":"18367418826115770822"},"user_tz":240},"id":"_n9ia_6ldmBp","outputId":"d4331858-1042-4d73-90a1-f71310b95e9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","import glob\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import os\n","from os import path\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["generate_dataset(\n","  dataset_path = '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Datasets/Full Dataset/AMR 5 New',\n","  source_dataset_path = '/content/drive/MyDrive/Mobile Robotics Project/Full Dataset/ABF',\n","  image_enhancement = adaptive_multiscale_retinex_5\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1e-TapMNjeK","executionInfo":{"status":"ok","timestamp":1680987199531,"user_tz":240,"elapsed":6908923,"user":{"displayName":"Awrod Haghi-Tabrizi","userId":"18367418826115770822"}},"outputId":"e9474267-b114-42b1-ad1c-5c3f96046eea"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating dataset...\n","\n","Dataset Path : /content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Datasets/Full Dataset/AMR 5 New\n","Source Dataset Path : /content/drive/MyDrive/Mobile Robotics Project/Full Dataset/ABF\n","Image Enhancement : <function adaptive_multiscale_retinex_5 at 0x7f029be3b310>\n","\n","Index 0/991...\n","Index 20/991...\n","Index 40/991...\n","Index 60/991...\n","Index 80/991...\n","Index 100/991...\n","Index 120/991...\n","Index 140/991...\n","Index 160/991...\n","Index 180/991...\n","Index 200/991...\n","Index 220/991...\n","Index 240/991...\n","Index 260/991...\n","Index 280/991...\n","Index 300/991...\n","Index 320/991...\n","Index 340/991...\n","Index 360/991...\n","Index 380/991...\n","Index 400/991...\n","Index 420/991...\n","Index 440/991...\n","Index 460/991...\n","Index 480/991...\n","Index 500/991...\n","Index 520/991...\n","Index 540/991...\n","Index 560/991...\n","Index 580/991...\n","Index 600/991...\n","Index 620/991...\n","Index 640/991...\n","Index 660/991...\n","Index 680/991...\n","Index 700/991...\n","Index 720/991...\n","Index 740/991...\n","Index 760/991...\n","Index 780/991...\n","Index 800/991...\n","Index 820/991...\n","Index 840/991...\n","Index 860/991...\n","Index 880/991...\n","Index 900/991...\n","Index 920/991...\n","Index 940/991...\n","Index 960/991...\n","Index 980/991...\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1680980172363,"user":{"displayName":"Awrod Haghi-Tabrizi","userId":"18367418826115770822"},"user_tz":240},"id":"l_85ZBigrzbI"},"outputs":[],"source":["# Dataset generator method\n","def generate_dataset(dataset_path, source_dataset_path, image_enhancement, verbose=True):\n","\n","  # Output header\n","  header = 'Generating dataset...\\n\\n'\n","  header += f'Dataset Path : {dataset_path}\\n'\n","  header += f'Source Dataset Path : {source_dataset_path}\\n'\n","  header += f'Image Enhancement : {image_enhancement}\\n'\n","  print(header)\n","\n","  # Create dataset folders\n","  if not path.exists(f'{dataset_path}'):\n","    os.mkdir(f'{dataset_path}')\n","  if not path.exists(f'{dataset_path}/image_0'):\n","    os.mkdir(f'{dataset_path}/image_0')\n","  if not path.exists(f'{dataset_path}/image_1'):\n","    os.mkdir(f'{dataset_path}/image_1')\n","\n","  # Method for getting the index from a dataset path\n","  def get_index_from_path(path):\n","    if 'image_0' in path:\n","      left_text = f'{source_dataset_path}/image_0/'\n","    elif 'image_1' in path:\n","      left_text = f'{source_dataset_path}/image_1/'\n","    right_text = '.png'\n","    left_idx = path.index(left_text)\n","    right_idx = path.index(right_text)\n","    res = ''\n","    for idx in range(left_idx + len(left_text), right_idx):\n","        res = res + path[idx]\n","    return res\n","\n","  # Loop through all source dataset images\n","  image_paths = zip( sorted(glob.glob(f'{source_dataset_path}/image_0/*.png')) , sorted(glob.glob(f'{source_dataset_path}/image_1/*.png')) )\n","  for i, (image_0_path, image_1_path) in enumerate(image_paths):\n","\n","    # Generate image_0 image\n","    idx = get_index_from_path(image_0_path)\n","    if not os.path.isfile(f'{dataset_path}/image_0/{idx}.png'):\n","      img = cv2.imread(image_0_path)\n","      img = image_enhancement(img)\n","      cv2.imwrite(f'{dataset_path}/image_0/{idx}.png', img)\n","\n","  # Generate image_1 image\n","    idx = get_index_from_path(image_1_path)\n","    if not os.path.isfile(f'{dataset_path}/image_1/{idx}.png'):\n","      img = cv2.imread(image_1_path)\n","      img = image_enhancement(img)\n","      cv2.imwrite(f'{dataset_path}/image_1/{idx}.png', img)\n","\n","    # Print progress\n","    if verbose and i % 20 == 0:\n","      print(f'Index {i}/{len(glob.glob(f\"{source_dataset_path}/image_0/*.png\"))}...')\n","\n","  # # Copy other dataset files\n","  # %cp -av '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Dataset Files/tartanair.yaml' '{dataset_path}/'\n","  # %cp -av '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Dataset Files/tartanair2.yaml' '{dataset_path}/'\n","  # %cp -av '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Dataset Files/tartanair3.yaml' '{dataset_path}/'\n","  # %cp -av '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Dataset Files/tartanair.yamlï€ºZone.Identifier' '{dataset_path}/'\n","  # %cp -av '/content/drive/MyDrive/Mobile Robotics Project/Image Enhancement/Dataset Files/times.txt' '{dataset_path}/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjwL6z-rBkh4"},"outputs":[],"source":["# Team 22\n","\n","def team_22_1(img):\n","\n","  src = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  res = np.zeros(src.shape, np.uint8)\n","  gui_small, gui_large = cv2.ximgproc.guidedFilter(src, src, 2, 0.1*0.1), cv2.ximgproc.guidedFilter(src, src, 2*10, 0.1*0.1)\n","  residual = gui_small - gui_large\n","  detail = gui_small + 5 * residual\n","  clahe = cv2.createCLAHE(clipLimit=8, tileGridSize=(8,8))\n","  res = clahe.apply(detail)\n","\n","  return res\n","\n","def team_22_color_1(img):\n","\n","  res = np.zeros(img.shape[:2], dtype=np.uint8)\n","  gui_small = cv2.ximgproc.guidedFilter(img, img, 2, 0.1*0.1)\n","  gui_large = cv2.ximgproc.guidedFilter(img, img, 2*10, 0.1*0.1)\n","  residual = gui_small - gui_large\n","  detail = gui_small + 5 * residual\n","  lab = cv2.cvtColor(detail, cv2.COLOR_BGR2LAB)\n","  lab_planes = list(cv2.split(lab))\n","  clahe = cv2.createCLAHE(clipLimit=8.0, tileGridSize=(8,8))\n","  lab_planes[0] = clahe.apply(lab_planes[0])\n","  lab = cv2.merge(tuple(lab_planes))\n","  res = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n","\n","  return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWb45OkouU7H"},"outputs":[],"source":["# Adaptive Histogram Equalization\n","\n","def adaptive_histogram_equalization_1(img, clipLimit=2.0, tileGridSize=(8,8)):\n","\n","  # Convert input image to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","  # Split the L, A, and B channels of the LAB image\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Create a CLAHE object with a clip limit of 2.0 and a tile size of 8x8\n","  clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","\n","  # Apply CLAHE to the L channel of the LAB image\n","  cl = clahe.apply(l_channel)\n","\n","  # Merge the enhanced L channel with the original A and B channels\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Convert the LAB image back to the BGR color space\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  return enhanced_img\n","\n","def adaptive_histogram_equalization_2(img, clipLimit=4.0, tileGridSize=(8,8)):\n","\n","  # Convert input image to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","  # Split the L, A, and B channels of the LAB image\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Create a CLAHE object with a clip limit of 2.0 and a tile size of 8x8\n","  clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","\n","  # Apply CLAHE to the L channel of the LAB image\n","  cl = clahe.apply(l_channel)\n","\n","  # Merge the enhanced L channel with the original A and B channels\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Convert the LAB image back to the BGR color space\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  return enhanced_img\n","\n","def adaptive_histogram_equalization_3(img, clipLimit=2.0, tileGridSize=(4,4)):\n","\n","  # Convert input image to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","  # Split the L, A, and B channels of the LAB image\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Create a CLAHE object with a clip limit of 2.0 and a tile size of 8x8\n","  clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","\n","  # Apply CLAHE to the L channel of the LAB image\n","  cl = clahe.apply(l_channel)\n","\n","  # Merge the enhanced L channel with the original A and B channels\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Convert the LAB image back to the BGR color space\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  return enhanced_img\n","\n","def adaptive_histogram_equalization_4(img, clipLimit=4.0, tileGridSize=(4,4)):\n","\n","  # Convert input image to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","  # Split the L, A, and B channels of the LAB image\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Create a CLAHE object with a clip limit of 2.0 and a tile size of 8x8\n","  clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","\n","  # Apply CLAHE to the L channel of the LAB image\n","  cl = clahe.apply(l_channel)\n","\n","  # Merge the enhanced L channel with the original A and B channels\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Convert the LAB image back to the BGR color space\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  return enhanced_img\n","\n","def adaptive_histogram_equalization_5(img, clipLimit=4.0, tileGridSize=(2,2)):\n","\n","  # Convert input image to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","  # Split the L, A, and B channels of the LAB image\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Create a CLAHE object with a clip limit of 2.0 and a tile size of 8x8\n","  clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n","\n","  # Apply CLAHE to the L channel of the LAB image\n","  cl = clahe.apply(l_channel)\n","\n","  # Merge the enhanced L channel with the original A and B channels\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Convert the LAB image back to the BGR color space\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  return enhanced_img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWeXu8kZNly3"},"outputs":[],"source":["# Adaptive multiscale retinex\n","\n","def adaptive_multiscale_retinex_1(image, sigma_list=[15, 80, 250], alpha=125, beta=46, gamma=15, gain=1):\n","\n","    # Convert image to float32 for processing\n","    image = np.float32(image)\n","\n","    # Compute the logarithm of the image\n","    log_image = np.log10(image + 1.0)\n","\n","    # Initialize the output image\n","    enhanced_image = np.zeros_like(image)\n","\n","    # Perform AMSR on each scale\n","    for sigma in sigma_list:\n","        # Apply Gaussian blur\n","        blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n","        # Compute the MSR component\n","        msr_component = log_image - blurred_image\n","        # Amplify the MSR component\n","        msr_component = alpha * msr_component\n","        # Normalize the MSR component\n","        msr_component = cv2.normalize(msr_component, None, 0, beta, cv2.NORM_MINMAX)\n","        # Exponentiate the MSR component\n","        msr_component = np.power(10, msr_component)\n","        # Add the MSR component to the enhanced image\n","        enhanced_image += msr_component\n","\n","    # Normalize the enhanced image\n","    enhanced_image = cv2.normalize(enhanced_image, None, 0, 255, cv2.NORM_MINMAX)\n","    # Convert the enhanced image back to uint8\n","    enhanced_image = np.uint8(enhanced_image)\n","\n","    # Adjust the enhancement level with the gain factor\n","    enhanced_image = cv2.addWeighted(image, gain, enhanced_image, 1 - gain, 0, dtype=cv2.CV_32F) # Explicitly specify the data type of the output image\n","\n","    return enhanced_image\n","\n","def adaptive_multiscale_retinex_2(image, sigma_list=[10, 25, 50, 100, 150, 200, 250], alpha=125, beta=46, gamma=15, gain=1):\n","\n","    # Convert image to float32 for processing\n","    image = np.float32(image)\n","\n","    # Compute the logarithm of the image\n","    log_image = np.log10(image + 1.0)\n","\n","    # Initialize the output image\n","    enhanced_image = np.zeros_like(image)\n","\n","    # Perform AMSR on each scale\n","    for sigma in sigma_list:\n","        # Apply Gaussian blur\n","        blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n","        # Compute the MSR component\n","        msr_component = log_image - blurred_image\n","        # Amplify the MSR component\n","        msr_component = alpha * msr_component\n","        # Normalize the MSR component\n","        msr_component = cv2.normalize(msr_component, None, 0, beta, cv2.NORM_MINMAX)\n","        # Exponentiate the MSR component\n","        msr_component = np.power(10, msr_component)\n","        # Add the MSR component to the enhanced image\n","        enhanced_image += msr_component\n","\n","    # Normalize the enhanced image\n","    enhanced_image = cv2.normalize(enhanced_image, None, 0, 255, cv2.NORM_MINMAX)\n","    # Convert the enhanced image back to uint8\n","    enhanced_image = np.uint8(enhanced_image)\n","\n","    # Adjust the enhancement level with the gain factor\n","    enhanced_image = cv2.addWeighted(image, gain, enhanced_image, 1 - gain, 0, dtype=cv2.CV_32F) # Explicitly specify the data type of the output image\n","\n","    return enhanced_image\n","\n","def adaptive_multiscale_retinex_3(image, sigma_list=list(np.linspace(5,255,21).astype(int)), alpha=125, beta=46, gamma=15, gain=1):\n","\n","    # Convert image to float32 for processing\n","    image = np.float32(image)\n","\n","    # Compute the logarithm of the image\n","    log_image = np.log10(image + 1.0)\n","\n","    # Initialize the output image\n","    enhanced_image = np.zeros_like(image)\n","\n","    # Perform AMSR on each scale\n","    for sigma in sigma_list:\n","        # Apply Gaussian blur\n","        blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n","        # Compute the MSR component\n","        msr_component = log_image - blurred_image\n","        # Amplify the MSR component\n","        msr_component = alpha * msr_component\n","        # Normalize the MSR component\n","        msr_component = cv2.normalize(msr_component, None, 0, beta, cv2.NORM_MINMAX)\n","        # Exponentiate the MSR component\n","        msr_component = np.power(10, msr_component)\n","        # Add the MSR component to the enhanced image\n","        enhanced_image += msr_component\n","\n","    # Normalize the enhanced image\n","    enhanced_image = cv2.normalize(enhanced_image, None, 0, 255, cv2.NORM_MINMAX)\n","    # Convert the enhanced image back to uint8\n","    enhanced_image = np.uint8(enhanced_image)\n","\n","    # Adjust the enhancement level with the gain factor\n","    enhanced_image = cv2.addWeighted(image, gain, enhanced_image, 1 - gain, 0, dtype=cv2.CV_32F) # Explicitly specify the data type of the output image\n","\n","    return enhanced_image\n","\n","def adaptive_multiscale_retinex_4(image, sigma_list=[10, 25, 50, 100, 150, 200, 250], alpha=200, beta=75, gamma=20, gain=1):\n","\n","    # Convert image to float32 for processing\n","    image = np.float32(image)\n","\n","    # Compute the logarithm of the image\n","    log_image = np.log10(image + 1.0)\n","\n","    # Initialize the output image\n","    enhanced_image = np.zeros_like(image)\n","\n","    # Perform AMSR on each scale\n","    for sigma in sigma_list:\n","        # Apply Gaussian blur\n","        blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n","        # Compute the MSR component\n","        msr_component = log_image - blurred_image\n","        # Amplify the MSR component\n","        msr_component = alpha * msr_component\n","        # Normalize the MSR component\n","        msr_component = cv2.normalize(msr_component, None, 0, beta, cv2.NORM_MINMAX)\n","        # Exponentiate the MSR component\n","        msr_component = np.power(10, msr_component)\n","        # Add the MSR component to the enhanced image\n","        enhanced_image += msr_component\n","\n","    # Normalize the enhanced image\n","    enhanced_image = cv2.normalize(enhanced_image, None, 0, 255, cv2.NORM_MINMAX)\n","    # Convert the enhanced image back to uint8\n","    enhanced_image = np.uint8(enhanced_image)\n","\n","    # Adjust the enhancement level with the gain factor\n","    enhanced_image = cv2.addWeighted(image, gain, enhanced_image, 1 - gain, 0, dtype=cv2.CV_32F) # Explicitly specify the data type of the output image\n","\n","    return enhanced_image\n","\n","def adaptive_multiscale_retinex_5(image, sigma_list=[10, 25, 50, 100, 150, 200, 250], alpha=100, beta=35, gamma=10, gain=1):\n","\n","    # Convert image to float32 for processing\n","    image = np.float32(image)\n","\n","    # Compute the logarithm of the image\n","    log_image = np.log10(image + 1.0)\n","\n","    # Initialize the output image\n","    enhanced_image = np.zeros_like(image)\n","\n","    # Perform AMSR on each scale\n","    for sigma in sigma_list:\n","        # Apply Gaussian blur\n","        blurred_image = cv2.GaussianBlur(log_image, (0, 0), sigma)\n","        # Compute the MSR component\n","        msr_component = log_image - blurred_image\n","        # Amplify the MSR component\n","        msr_component = alpha * msr_component\n","        # Normalize the MSR component\n","        msr_component = cv2.normalize(msr_component, None, 0, beta, cv2.NORM_MINMAX)\n","        # Exponentiate the MSR component\n","        msr_component = np.power(10, msr_component)\n","        # Add the MSR component to the enhanced image\n","        enhanced_image += msr_component\n","\n","    # Normalize the enhanced image\n","    enhanced_image = cv2.normalize(enhanced_image, None, 0, 255, cv2.NORM_MINMAX)\n","    # Convert the enhanced image back to uint8\n","    enhanced_image = np.uint8(enhanced_image)\n","\n","    # Adjust the enhancement level with the gain factor\n","    enhanced_image = cv2.addWeighted(image, gain, enhanced_image, 1 - gain, 0, dtype=cv2.CV_32F) # Explicitly specify the data type of the output image\n","\n","    return enhanced_image"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7mtp38mGfMZusHggOBIV5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}